Model: Random Forest
Accuracy: 0.7970191625266146
              precision    recall  f1-score   support

           0       0.83      0.91      0.87      1036
           1       0.66      0.48      0.56       373

    accuracy                           0.80      1409
   macro avg       0.74      0.70      0.71      1409
weighted avg       0.78      0.80      0.79      1409

========================================

Model: Logistic Regression
Accuracy: 0.8026969481902059
              precision    recall  f1-score   support

           0       0.85      0.89      0.87      1036
           1       0.65      0.56      0.60       373

    accuracy                           0.80      1409
   macro avg       0.75      0.72      0.73      1409
weighted avg       0.80      0.80      0.80      1409

========================================
Model: XGBoost
Accuracy: 0.7863733144073811
              precision    recall  f1-score   support

           0       0.84      0.87      0.86      1036
           1       0.61      0.55      0.58       373

    accuracy                           0.79      1409
   macro avg       0.72      0.71      0.72      1409
weighted avg       0.78      0.79      0.78      1409

========================================
Model: SVM
Accuracy: 0.808374733853797
              precision    recall  f1-score   support

           0       0.84      0.91      0.87      1036
           1       0.67      0.54      0.60       373

    accuracy                           0.81      1409
   macro avg       0.76      0.72      0.74      1409
weighted avg       0.80      0.81      0.80      1409

========================================
Model: Naive Bayes
Accuracy: 0.5911994322214337
              precision    recall  f1-score   support

           0       0.79      0.61      0.69      1036
           1       0.33      0.54      0.41       373

    accuracy                           0.59      1409
   macro avg       0.56      0.58      0.55      1409
weighted avg       0.67      0.59      0.61      1409

========================================
Model: Decision Tree
Accuracy: 0.7189496096522356
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1036
           1       0.47      0.48      0.47       373

    accuracy                           0.72      1409
   macro avg       0.64      0.64      0.64      1409
weighted avg       0.72      0.72      0.72      1409

========================================
Model: K-Nearest Neighbors
Accuracy: 0.6891412349183819
              precision    recall  f1-score   support

           0       0.74      0.88      0.81      1036
           1       0.31      0.15      0.20       373

    accuracy                           0.69      1409
   macro avg       0.53      0.52      0.50      1409
weighted avg       0.63      0.69      0.65      1409

========================================
Model: AdaBoost
Accuracy: 0.8076650106458482
              precision    recall  f1-score   support

           0       0.85      0.90      0.87      1036
           1       0.66      0.56      0.61       373

    accuracy                           0.81      1409
   macro avg       0.76      0.73      0.74      1409
weighted avg       0.80      0.81      0.80      1409

========================================
Model: Bagging
Accuracy: 0.7892122072391767
              precision    recall  f1-score   support

           0       0.82      0.91      0.86      1036
           1       0.64      0.46      0.54       373

    accuracy                           0.79      1409
   macro avg       0.73      0.68      0.70      1409
weighted avg       0.78      0.79      0.78      1409

========================================
Model: Extra Trees
Accuracy: 0.794180269694819
              precision    recall  f1-score   support

           0       0.83      0.90      0.87      1036
           1       0.65      0.49      0.56       373

    accuracy                           0.79      1409
   macro avg       0.74      0.70      0.71      1409
weighted avg       0.78      0.79      0.78      1409

========================================
Model: Gradient Boosting
Accuracy: 0.808374733853797
              precision    recall  f1-score   support

           0       0.84      0.91      0.87      1036
           1       0.68      0.52      0.59       373

    accuracy                           0.81      1409
   macro avg       0.76      0.72      0.73      1409
weighted avg       0.80      0.81      0.80      1409

========================================
Best model saved: SVC(kernel='linear', probability=True)